\chapter{Foundations}
\label{chap:foundations}

In this chapter topics that are tackled during the lecture are introduced in a basic fashion. This includes agents, sensor, actuators, communication, etc\dots

\section{Agents}
\label{sec:agents}

Although not every agent is autonomous, our focus in this lecture is to design autnomous agents. Autonomous means, that the agent is not controlled from some external entitiy. It only perceives its environment and acts in order to change it. Why it tries to change its environment depends on the agent's properties. Agents can be reactive or proactive, they can communicate with other agents, remember the history of the environment, and predict the future of the environment according to some model. As a designer of the agents, you need to decide what kind of agents you need to achieve your goal. The famous book \emph{Artificial Intelligence \textendash\ A Modern Approach}, written by Russel and Norvic, elaborates properties of agents and environment in chapter two. The book is available in our library. It is recommmended to read chapter two for your exam preparations.

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[every node/.append style={thick}]
    \node(Agent)[plan, minimum width=2.5cm] at (0,0) {Agent};
    \node(Environment) [plan, minimum width=2.5cm] at (0,-1) {Environment};
    \draw[->, bend left] (Agent.south east) to node[right] {act} (Environment.north east);
    \draw[->, bend left] (Environment.north west) to node[left] {perceive} (Agent.south west);
  \end{tikzpicture}
  \caption{Simple Control Loop}
  \label{fig:simplecontrolloop}
\end{figure}

Usually it is believed that the agent is interacting with its environment \textendash whatever that environment is. This relation is often depicted as an agent-environment cycle (see Figure~\ref{fig:simplecontrolloop}). As mentioned before, the details of an agent architecture do vary from use case to use case.

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[every node/.append style={thick}]
    \node(Knowledge)[anchor=center, draw=ukorange!85, fill=ukorange!10, rounded corners, text width=2.5cm, align=center] at (3,-1.3) {Symbolic Knowledge};
    
    \node(Data) at (0,0) {Data Layers};
    \node(SymbolLayer)[highLayer, anchor=north] at (Data.south) {};
    \node(SymbolLayerText)[anchor=north west] at (SymbolLayer.north west) {\tiny{\textbf{Symbol Layer}}};
    \node(SymbolLayerData)[data] at (SymbolLayer.south west) {\tiny{\textbf{Data:}\\[0.5em]Symbols, Rules,\\ Relations}};

    \node(IntermediateLayer)[midLayer, anchor=north west] at (SymbolLayer.south west) {};
    \node(IntermediateLayerText)[anchor=north west] at (IntermediateLayer.north west) {\tiny{\textbf{Intermediate Layer}}};
    \node(IntermediateLayerData)[data] at (IntermediateLayer.south west) {\tiny{\textbf{Data:}\\[0.5em]Feature Vectors, Raw Map}};

    \node(SensorimotorLayer)[lowLayer, anchor=north west] at (IntermediateLayer.south west) {};
    \node(SensorimotorLayerText)[anchor=north west] at (SensorimotorLayer.north west) {\tiny{\textbf{Sensorimotor Layer}}};
    \node(SensorimotorLayerData)[data] at (SensorimotorLayer.south west) {\tiny{\textbf{Data:}\\[0.5em]Raw Data}};

    \node(ButtomUp)[single arrow, shape border rotate=90, draw, anchor=center, minimum height=5.02cm, xshift=-1cm, text width=1cm, align=center] at (IntermediateLayer.west) {\tiny{Data Abstraction}};
    \draw[->, bend right] (IntermediateLayerData.east) to node [processingArrow] {\tiny{Symbol\\Grounding,\\Anchoring}} (SymbolLayerData.south east);
    \draw[->, bend right] (SensorimotorLayerData.east) to node [processingArrow] {\tiny{Smoothing,\\ Filtering}} (IntermediateLayerData.south east);
    \draw[->, bend left] (SymbolLayerData.east) to node [above, xshift=3mm] {\tiny{Updates}} (Knowledge.west);

    \node(Processing) at (6,0) {Control Layers};
    \node(DeliberateLayer)[highLayer, anchor=north] at (Processing.south) {};
    \node(DeliberateLayerText)[anchor=north west] at (DeliberateLayer.north west) {\tiny{\textbf{Deliberation Layer}}};
    \node(DeliberateLayerData)[data] at (DeliberateLayer.south west) {\tiny{\textbf{Control:}\\[0.5em]Communication, Planning, Strategy Evaluation}};

    \node(SequencerLayer)[midLayer, anchor=north west] at (DeliberateLayer.south west) {};
    \node(SequencerLayerText)[anchor=north west] at (SequencerLayer.north west) {\tiny{\textbf{Sequencer Layer}}};
    \node(SequencerLayerData)[data] at (SequencerLayer.south west) {\tiny{\textbf{Control:}\\[0.5em]Path Planning, Strategy}};

    \node(ControlLayer)[lowLayer, anchor=north west] at (SequencerLayer.south west) {};
    \node(ControlLayerText)[anchor=north west] at (ControlLayer.north west) {\tiny\textbf{{Reactive Control Layer}}};
    \node(ControlLayerData)[data] at (ControlLayer.south west) {\tiny{\textbf{Control:}\\[0.5em]Reaction,\\Controlling}};
    
    \node(TopDown)[single arrow, shape border rotate=270, draw, anchor=center, minimum height=5.02cm, xshift=+1cm, text width=1cm, align=center] at (SequencerLayer.east) {\tiny{Decision Making and Execution}};
    \draw[<-, bend left] (SequencerLayerData.west) to node [processingArrow, text width=1cm, left, yshift=2mm] {\tiny{Strategy\\Adaption}} (DeliberateLayerData.south west);
    \draw[<-, bend left] (ControlLayerData.west) to node [processingArrow, text width=1.1cm, left, yshift=2mm] {\tiny{Behaviour\\Adaption}} (SequencerLayerData.south west);
    \draw[->, bend left] (Knowledge.east) to node [above, xshift=-3mm] {\tiny{Queries}} (DeliberateLayerData.west);
    
    \node(Environment) [minimum width=9cm, minimum height=0.8cm, draw=black!85] at (3,-7) {Environment};
    \draw[->, bend right] (ControlLayerData.west) to node [left] {\tiny{act}} ([xshift=1.3cm]Environment.north);
    \draw[->, bend right] ([xshift=-1.8cm]Environment.north) to node [right] {\tiny{sense}} (SensorimotorLayerData.east);
  \end{tikzpicture}
  \caption{Control Loop}
  \label{fig:controlloop}
\end{figure}

 In Figure~\ref{fig:controlloop} an overview of the details of a state-of-the-art robot control system is shown. The Data Layers on the left hand side represent the utilised algorithms to gain information and knowledge from raw sensor data. During the data processing, the data are continuously filtered, condensed, and abstracted until symbols and relations can be integrated into the symbolic knowledge representation. This knowledge is required by the algorithms on the right hand side of Figure~\ref{fig:controlloop}. The Deliberation Layer, including algorithms for planning, communication, and strategy evaluation, computes its decisions based on the knowledge of the symbolic knowledge representation. The results are processed by the Sequencer Layer and transformed into commands for controlling actuators of the robot. 

\section{Sensors}
\label{sec:sensor}

\section{Actuators}
\label{sec:actuators}

\section{Communication}
\label{sec:communication}